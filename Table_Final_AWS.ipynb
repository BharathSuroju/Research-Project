{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verispy import VERIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8539 json files.\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'C:/bharath/project/VCDB-master1/data/json/validated'\n",
    "v = VERIS(json_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7cb55b2a5a31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_veris\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson_to_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'v' is not defined"
     ]
    }
   ],
   "source": [
    "df_veris = v.json_to_df(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_veris' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-814bc6245df4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_veris\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_veris\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'action.social.vector.SMS'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'summary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_veris' is not defined"
     ]
    }
   ],
   "source": [
    "df_veris[df_veris['action.social.vector.SMS'] == True ]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "8534    False\n",
       "8535    False\n",
       "8536    False\n",
       "8537    False\n",
       "8538    False\n",
       "Name: action.social.vector.SMS, Length: 8534, dtype: bool"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_veris['action.social.vector.SMS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5       00163384-B4D7-46D5-9E6F-543DFB00F598\n",
       "1203    18086BDC-29DD-46F7-8A05-A372C392CA95\n",
       "2370    18086BDC-29DD-46F7-8A05-A372C392CA95\n",
       "7019    d24d7280-6b0c-11e7-9b43-bf152d61c1c6\n",
       "8072    ad2653d0-d3bd-11e8-9659-2bc8d207b0aa\n",
       "Name: incident_id, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicateRowsDF = df_veris[df_veris.duplicated(['incident_id'])]\n",
    "duplicateRowsDF['incident_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veris.drop(8072,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: incident_id, dtype: object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicateRowsDF = df_veris[df_veris.duplicated(['incident_id'])]\n",
    "duplicateRowsDF['incident_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfi = df_veris[['incident_id','source_id','summary','notes']]\n",
    "\n",
    "enumlist = ['security_incident','confidence']\n",
    "i = 1\n",
    "dflist=[]\n",
    "dfxlist=[]\n",
    "for j in enumlist:\n",
    "    y = 'df' + str(i)\n",
    "    y = df_veris.filter(regex = (j))\n",
    "    dflist.append(y)\n",
    "    z = 'dfx' + str(i)\n",
    "    z = pd.DataFrame({j:[]})\n",
    "    dfxlist.append(z)\n",
    "    i+=1\n",
    "for dataframe in dflist:\n",
    "    for col in dataframe.columns:\n",
    "        dataframe.loc[:,col]= dataframe.loc[:,col].apply(lambda x: col.split('.')[-1] if x else '')\n",
    "m = 0\n",
    "for i,j in zip(dfxlist,dflist):\n",
    "    i[enumlist[m]] = j.apply(lambda x: ','.join(x), axis = 1)\n",
    "    m+=1\n",
    "def get_first(pats):\n",
    "    str1 = ''\n",
    "    pats = [pat for pat in pats.split(',') if len(pat) > 0]\n",
    "    for i in pats: \n",
    "        str1 = str1 + i\n",
    "    return str1\n",
    "for dataframe in dfxlist:\n",
    "    for col in dataframe.columns:\n",
    "        dataframe.loc[:,col] = dataframe.loc[:,col].apply(lambda x: get_first(x))\n",
    "#finallist = list(dfi) + dfxlist\n",
    "incident_Tracking = pd.concat([dfi] + dfxlist ,axis=1, sort=False)\n",
    "writer = pd.ExcelWriter(r'incident_Tracking.xlsx', engine='xlsxwriter',options={'strings_to_urls': False})\n",
    "incident_Tracking.to_excel(writer,index = False)\n",
    "writer.close()\n",
    "incident_Tracking.rename(columns=lambda x: x.replace('.', '_'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://postgres:Research2020@database-1.cccwhhevip1x.us-east-2.rds.amazonaws.com:5432/postgres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "incident_Tracking.to_sql(\"incident_Tracking\", engine,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfi = df_veris[['incident_id','victim.industry','victim.industry.name','victim.industry','victim.locations_affected','victim.notes','victim.region','victim.revenue.amount','victim.secondary.amount','victim.secondary.notes','victim.secondary.victim_id','victim.state','victim.victim_id']]\n",
    "\n",
    "enumlist = ['victim.employee_count','victim.revenue.iso_currency_code','victim.orgsize',\n",
    "'victim.industry2','victim.industry3','victim.country']\n",
    "i = 1\n",
    "dflist=[]\n",
    "dfxlist=[]\n",
    "for j in enumlist:\n",
    "    y = 'df' + str(i)\n",
    "    y = df_veris.filter(regex = (j))\n",
    "    dflist.append(y)\n",
    "    z = 'dfx' + str(i)\n",
    "    z = pd.DataFrame({j:[]})\n",
    "    dfxlist.append(z)\n",
    "    i+=1\n",
    "for dataframe in dflist:\n",
    "    for col in dataframe.columns:\n",
    "        dataframe.loc[:,col]= dataframe.loc[:,col].apply(lambda x: col.split('.')[-1] if x else '')\n",
    "m = 0\n",
    "for i,j in zip(dfxlist,dflist):\n",
    "    i[enumlist[m]] = j.apply(lambda x: ','.join(x), axis = 1)\n",
    "    m+=1\n",
    "def get_first(pats):\n",
    "    str1 = ''\n",
    "    pats = [pat for pat in pats.split(',') if len(pat) > 0]\n",
    "    count = 0\n",
    "    for i in pats: \n",
    "        if count==0:\n",
    "            str1 = str1 + i \n",
    "        else:\n",
    "            str1 = str1 + ',' + i\n",
    "        count+=1\n",
    "    return str1\n",
    "for dataframe in dfxlist:\n",
    "    for col in dataframe.columns:\n",
    "        dataframe.loc[:,col] = dataframe.loc[:,col].apply(lambda x: get_first(x))\n",
    "#finallist = list(dfi) + dfxlist\n",
    "victim_demographics = pd.concat([dfi] + dfxlist ,axis=1, sort=False)\n",
    "writer = pd.ExcelWriter(r'victim_demographics.xlsx', engine='xlsxwriter',options={'strings_to_urls': False})\n",
    "victim_demographics.to_excel(writer,index = False)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_demographics.rename(columns=lambda x: x.replace('.', '_'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_id</th>\n",
       "      <th>victim_industry</th>\n",
       "      <th>victim_industry_name</th>\n",
       "      <th>victim_industry</th>\n",
       "      <th>victim_locations_affected</th>\n",
       "      <th>victim_notes</th>\n",
       "      <th>victim_region</th>\n",
       "      <th>victim_revenue_amount</th>\n",
       "      <th>victim_secondary_amount</th>\n",
       "      <th>victim_secondary_notes</th>\n",
       "      <th>victim_secondary_victim_id</th>\n",
       "      <th>victim_state</th>\n",
       "      <th>victim_victim_id</th>\n",
       "      <th>victim_employee_count</th>\n",
       "      <th>victim_revenue_iso_currency_code</th>\n",
       "      <th>victim_orgsize</th>\n",
       "      <th>victim_industry2</th>\n",
       "      <th>victim_industry3</th>\n",
       "      <th>victim_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001AA7F-C601-424A-B2B8-BE6C9F5164E7</td>\n",
       "      <td>923140</td>\n",
       "      <td>Public</td>\n",
       "      <td>923140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[019021]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MO</td>\n",
       "      <td>United States Department of Veterans Affairs</td>\n",
       "      <td>Over 100000</td>\n",
       "      <td></td>\n",
       "      <td>Large</td>\n",
       "      <td>industry2,92</td>\n",
       "      <td>industry3</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0008DADB-E83D-4278-A19A-CEE01610CF43</td>\n",
       "      <td>621111</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>621111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[019021]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OR</td>\n",
       "      <td>Corvallis Clinic</td>\n",
       "      <td>101 to 1000</td>\n",
       "      <td></td>\n",
       "      <td>Small</td>\n",
       "      <td>industry2,62</td>\n",
       "      <td>industry3</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000D403E-2DC9-4EA7-9294-BD3938D1C3C7</td>\n",
       "      <td>622110</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>622110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[019021]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Jersey City Medical Center</td>\n",
       "      <td>1001 to 10000</td>\n",
       "      <td></td>\n",
       "      <td>Large</td>\n",
       "      <td>industry2,62</td>\n",
       "      <td>industry3</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0012CC25-9167-40D8-8FE3-3D0DFD8FB6BB</td>\n",
       "      <td>51919</td>\n",
       "      <td>Information</td>\n",
       "      <td>51919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[150154]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Universal Jobmatch</td>\n",
       "      <td>Unknown</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>industry2,51</td>\n",
       "      <td>industry3</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00163384-B4D7-46D5-9E6F-543DFB00F598</td>\n",
       "      <td>923140</td>\n",
       "      <td>Public</td>\n",
       "      <td>923140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[019021]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PA</td>\n",
       "      <td>United States Department of Veterans Affairs</td>\n",
       "      <td>Over 100000</td>\n",
       "      <td></td>\n",
       "      <td>Large</td>\n",
       "      <td>industry2,92</td>\n",
       "      <td>industry3</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8534</th>\n",
       "      <td>FFD31FE4-976B-48CA-A111-EF84EBAB9B0F</td>\n",
       "      <td>524210</td>\n",
       "      <td>Finance</td>\n",
       "      <td>524210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[019021]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NC</td>\n",
       "      <td>Willis North America</td>\n",
       "      <td>Unknown</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>industry2,52</td>\n",
       "      <td>industry3</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8535</th>\n",
       "      <td>cc630a80-d57a-11e9-8597-ff36b2265d64</td>\n",
       "      <td>517</td>\n",
       "      <td>Information</td>\n",
       "      <td>517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[019021]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GA</td>\n",
       "      <td>Verizon</td>\n",
       "      <td>Over 100000</td>\n",
       "      <td></td>\n",
       "      <td>Large</td>\n",
       "      <td>industry2,51</td>\n",
       "      <td>industry3</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8536</th>\n",
       "      <td>FFDA2281-8053-4315-B613-330EB09A4BEE</td>\n",
       "      <td>541990</td>\n",
       "      <td>Professional</td>\n",
       "      <td>541990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[019021]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OH</td>\n",
       "      <td>Instant Refund Tax Service</td>\n",
       "      <td>1 to 10</td>\n",
       "      <td></td>\n",
       "      <td>Small</td>\n",
       "      <td>industry2,54</td>\n",
       "      <td>industry3</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8537</th>\n",
       "      <td>FFDC6655-E421-4BEC-835F-1BDFEC4F6C70</td>\n",
       "      <td>622</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[150154]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Walking on Air Clinic</td>\n",
       "      <td>Unknown</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>industry2,62</td>\n",
       "      <td>industry3</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8538</th>\n",
       "      <td>FFE36843-D23A-484F-A9B8-1338C9BE49CD</td>\n",
       "      <td>923140</td>\n",
       "      <td>Public</td>\n",
       "      <td>923140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[019021]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KS</td>\n",
       "      <td>United States Department of Veterans Affairs</td>\n",
       "      <td>Over 100000</td>\n",
       "      <td></td>\n",
       "      <td>Large</td>\n",
       "      <td>industry2,92</td>\n",
       "      <td>industry3</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8534 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               incident_id victim_industry  \\\n",
       "0     0001AA7F-C601-424A-B2B8-BE6C9F5164E7          923140   \n",
       "1     0008DADB-E83D-4278-A19A-CEE01610CF43          621111   \n",
       "2     000D403E-2DC9-4EA7-9294-BD3938D1C3C7          622110   \n",
       "3     0012CC25-9167-40D8-8FE3-3D0DFD8FB6BB           51919   \n",
       "4     00163384-B4D7-46D5-9E6F-543DFB00F598          923140   \n",
       "...                                    ...             ...   \n",
       "8534  FFD31FE4-976B-48CA-A111-EF84EBAB9B0F          524210   \n",
       "8535  cc630a80-d57a-11e9-8597-ff36b2265d64             517   \n",
       "8536  FFDA2281-8053-4315-B613-330EB09A4BEE          541990   \n",
       "8537  FFDC6655-E421-4BEC-835F-1BDFEC4F6C70             622   \n",
       "8538  FFE36843-D23A-484F-A9B8-1338C9BE49CD          923140   \n",
       "\n",
       "     victim_industry_name victim_industry  victim_locations_affected  \\\n",
       "0                  Public          923140                        NaN   \n",
       "1              Healthcare          621111                        NaN   \n",
       "2              Healthcare          622110                        NaN   \n",
       "3             Information           51919                        NaN   \n",
       "4                  Public          923140                        NaN   \n",
       "...                   ...             ...                        ...   \n",
       "8534              Finance          524210                        NaN   \n",
       "8535          Information             517                        NaN   \n",
       "8536         Professional          541990                        NaN   \n",
       "8537           Healthcare             622                        NaN   \n",
       "8538               Public          923140                        NaN   \n",
       "\n",
       "     victim_notes victim_region  victim_revenue_amount  \\\n",
       "0             NaN      [019021]                    NaN   \n",
       "1             NaN      [019021]                    NaN   \n",
       "2             NaN      [019021]                    NaN   \n",
       "3             NaN      [150154]                    NaN   \n",
       "4             NaN      [019021]                    NaN   \n",
       "...           ...           ...                    ...   \n",
       "8534          NaN      [019021]                    NaN   \n",
       "8535          NaN      [019021]                    NaN   \n",
       "8536          NaN      [019021]                    NaN   \n",
       "8537          NaN      [150154]                    NaN   \n",
       "8538          NaN      [019021]                    NaN   \n",
       "\n",
       "      victim_secondary_amount victim_secondary_notes  \\\n",
       "0                         NaN                    NaN   \n",
       "1                         NaN                    NaN   \n",
       "2                         NaN                    NaN   \n",
       "3                         NaN                    NaN   \n",
       "4                         NaN                    NaN   \n",
       "...                       ...                    ...   \n",
       "8534                      NaN                    NaN   \n",
       "8535                      NaN                    NaN   \n",
       "8536                      NaN                    NaN   \n",
       "8537                      NaN                    NaN   \n",
       "8538                      NaN                    NaN   \n",
       "\n",
       "     victim_secondary_victim_id victim_state  \\\n",
       "0                           NaN           MO   \n",
       "1                           NaN           OR   \n",
       "2                           NaN           NJ   \n",
       "3                           NaN          NaN   \n",
       "4                           NaN           PA   \n",
       "...                         ...          ...   \n",
       "8534                        NaN           NC   \n",
       "8535                        NaN           GA   \n",
       "8536                        NaN           OH   \n",
       "8537                        NaN          NaN   \n",
       "8538                        NaN           KS   \n",
       "\n",
       "                                  victim_victim_id victim_employee_count  \\\n",
       "0     United States Department of Veterans Affairs           Over 100000   \n",
       "1                                 Corvallis Clinic           101 to 1000   \n",
       "2                       Jersey City Medical Center         1001 to 10000   \n",
       "3                               Universal Jobmatch               Unknown   \n",
       "4     United States Department of Veterans Affairs           Over 100000   \n",
       "...                                            ...                   ...   \n",
       "8534                          Willis North America               Unknown   \n",
       "8535                                       Verizon           Over 100000   \n",
       "8536                    Instant Refund Tax Service               1 to 10   \n",
       "8537                         Walking on Air Clinic               Unknown   \n",
       "8538  United States Department of Veterans Affairs           Over 100000   \n",
       "\n",
       "     victim_revenue_iso_currency_code victim_orgsize victim_industry2  \\\n",
       "0                                              Large     industry2,92   \n",
       "1                                              Small     industry2,62   \n",
       "2                                              Large     industry2,62   \n",
       "3                                                        industry2,51   \n",
       "4                                              Large     industry2,92   \n",
       "...                               ...            ...              ...   \n",
       "8534                                                     industry2,52   \n",
       "8535                                           Large     industry2,51   \n",
       "8536                                           Small     industry2,54   \n",
       "8537                                                     industry2,62   \n",
       "8538                                           Large     industry2,92   \n",
       "\n",
       "     victim_industry3 victim_country  \n",
       "0           industry3             US  \n",
       "1           industry3             US  \n",
       "2           industry3             US  \n",
       "3           industry3             GB  \n",
       "4           industry3             US  \n",
       "...               ...            ...  \n",
       "8534        industry3             US  \n",
       "8535        industry3             US  \n",
       "8536        industry3             US  \n",
       "8537        industry3             GB  \n",
       "8538        industry3             US  \n",
       "\n",
       "[8534 rows x 19 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "victim_demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_demographics.to_sql(\"victim_demographics\", engine,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfi = df_veris[['incident_id','actor.external.name','actor.external.notes','actor.external.region','actor.internal.notes','actor.partner.industry','actor.partner.name',\n",
    "'actor.partner.notes','actor.partner.region','actor.unknown.notes','actor.partner.industry2']]\n",
    "\n",
    "enumlist = ['actor.external.country','actor.external.motive','actor.external.variety','actor.internal.job_change'\n",
    ",'actor.internal.motive','actor.internal.variety','actor.partner.country','actor.partner.motive','plus.event_chain.actor']\n",
    "i = 1\n",
    "dflist=[]\n",
    "dfxlist=[]\n",
    "for j in enumlist:\n",
    "    y = 'df' + str(i)\n",
    "    y = df_veris.filter(regex = (j))\n",
    "    dflist.append(y)\n",
    "    z = 'dfx' + str(i)\n",
    "    z = pd.DataFrame({j:[]})\n",
    "    dfxlist.append(z)\n",
    "    i+=1\n",
    "for dataframe in dflist:\n",
    "    for col in dataframe.columns:\n",
    "        dataframe.loc[:,col]= dataframe.loc[:,col].apply(lambda x: col.split('.')[-1] if x else '')\n",
    "m = 0\n",
    "for i,j in zip(dfxlist,dflist):\n",
    "    i[enumlist[m]] = j.apply(lambda x: ','.join(x), axis = 1)\n",
    "    m+=1\n",
    "def get_first(pats):\n",
    "    str1 = ''\n",
    "    pats = str(pats)\n",
    "    pats = [pat for pat in pats.split(',') if len(pat) > 0]\n",
    "    count = 0\n",
    "    for i in pats: \n",
    "        if count==0:\n",
    "            str1 = str1 + i \n",
    "        else:\n",
    "            str1 = str1 + ',' + i\n",
    "        count+=1\n",
    "    return str1\n",
    "for dataframe in dfxlist:\n",
    "    for col in dataframe.columns:\n",
    "        dataframe.loc[:,col] = dataframe.loc[:,col].apply(lambda x: get_first(x))\n",
    "#finallist = list(dfi) + dfxlist\n",
    "Actor_Info = pd.concat([dfi] + dfxlist ,axis=1, sort=False)\n",
    "writer = pd.ExcelWriter(r'Actor_Info.xlsx', engine='xlsxwriter',options={'strings_to_urls': False})\n",
    "Actor_Info.to_excel(writer,index = False)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Actor_Info.rename(columns=lambda x: x.replace('.', '_'), inplace=True)\n",
    "Actor_Info.to_sql(\"Actor_Info\", engine,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfi = df_veris[['incident_id','action.environmental.notes',\n",
    "'action.error.notes',\n",
    "'action.hacking.notes',\n",
    "'action.malware.name',\n",
    "'action.malware.notes',\n",
    "'action.misuse.notes',\n",
    "'action.physical.notes',\n",
    "'action.social.notes',\n",
    "'action.unknown.notes',\n",
    "'action.Malware',\n",
    "'action.Hacking',\n",
    "'action.Social',\n",
    "'action.Physical',\n",
    "'action.Misuse',\n",
    "'action.Error',\n",
    "'action.Environmental',\n",
    "'action.hacking.cve',\n",
    "'action.malware.cve',                \n",
    "'action.Unknown']]\n",
    "\n",
    "enumlist = ['action.environmental.variety',\n",
    "'action.error.variety',\n",
    "'action.error.vector',\n",
    "'action.hacking.result',\n",
    "'action.hacking.variety',\n",
    "'action.hacking.vector',\n",
    "'action.malware.result',\n",
    "'action.malware.variety',\n",
    "'action.malware.result',\n",
    "'action.malware.variety',\n",
    "'action.malware.vector',\n",
    "'action.misuse.result',\n",
    "'action.misuse.variety',\n",
    "'action.misuse.vector',\n",
    "'action.physical.result',\n",
    "'action.physical.variety',\n",
    "'action.physical.vector',\n",
    "'action.social.result',\n",
    "'action.social.target',\n",
    "'action.social.variety',\n",
    "'action.social.vector',\n",
    "'action.unknown.result',\n",
    "'cost_corrective_action.'\n",
    "]\n",
    "i = 1\n",
    "dflist=[]\n",
    "dfxlist=[]\n",
    "for j in enumlist:\n",
    "    y = 'df' + str(i)\n",
    "    y = df_veris.filter(regex = (j))\n",
    "    dflist.append(y)\n",
    "    z = 'dfx' + str(i)\n",
    "    z = pd.DataFrame({j:[]})\n",
    "    dfxlist.append(z)\n",
    "    i+=1\n",
    "for dataframe in dflist:\n",
    "    for col in dataframe.columns:\n",
    "        dataframe.loc[:,col]= dataframe.loc[:,col].apply(lambda x: col.split('.')[-1] if x else '')\n",
    "m = 0\n",
    "for i,j in zip(dfxlist,dflist):\n",
    "    i[enumlist[m]] = j.apply(lambda x: ','.join(x), axis = 1)\n",
    "    m+=1\n",
    "def get_first(pats):\n",
    "    str1 = ''\n",
    "    #pats = str(pats)\n",
    "    pats = [pat for pat in pats.split(',') if len(pat) > 0]\n",
    "    count = 0\n",
    "    for i in pats: \n",
    "        if count==0:\n",
    "            str1 = str1 + i \n",
    "        else:\n",
    "            str1 = str1 + ',' + i\n",
    "        count+=1\n",
    "    return str1\n",
    "for dataframe in dfxlist:\n",
    "    for col in dataframe.columns:\n",
    "        dataframe.loc[:,col] = dataframe.loc[:,col].apply(lambda x: get_first(x))\n",
    "#finallist = list(dfi) + dfxlist\n",
    "Action_Info = pd.concat([dfi] + dfxlist ,axis=1, sort=False)\n",
    "writer = pd.ExcelWriter(r'Action_Info.xlsx', engine='xlsxwriter',options={'strings_to_urls': False})\n",
    "Action_Info.to_excel(writer,index = False)\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Action_Info.rename(columns=lambda x: x.replace('.', '_'), inplace=True)\n",
    "Action_Info.to_sql(\"Action_Info\", engine,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_veris.columns = df_veris.columns.to_series().apply(lambda x: x.strip())\n",
    "dfi = df_veris[['incident_id','action.environmental.notes',\n",
    "'asset.assets.amount.Other',\n",
    "'asset.assets.amount.Unknown',\n",
    "'asset.assets.variety.Unknown',\n",
    "'asset.notes',\n",
    "'asset.total_amount','plus.asset.total','plus.asset_os']]\n",
    "\n",
    "enumlist = ['asset.assets.amount.E',\n",
    "'asset.assets.amount.M',\n",
    "'asset.assets.amount.N',\n",
    "'asset.assets.amount.P ',\n",
    "'asset.assets.amount.S',\n",
    "'asset.assets.amount.T',\n",
    "'asset.assets.amount.U ',\n",
    "'asset.assets.variety.E',\n",
    "'asset.assets.variety.M',\n",
    "'asset.assets.variety.N',\n",
    "'asset.assets.variety.Other',\n",
    "'asset.assets.variety.P',\n",
    "'asset.assets.variety.S',\n",
    "'asset.assets.variety.T',\n",
    "'asset.assets.variety.U',\n",
    "'asset.cloud',\n",
    "'asset.country',\n",
    "'asset.governance',\n",
    "'asset.hosting',\n",
    "'asset.management',\n",
    "'asset.ownership',\n",
    "'plus.event_chain.asset',\n",
    "'asset.variety'\n",
    "]\n",
    "i = 1\n",
    "dflist=[]\n",
    "dfxlist=[]\n",
    "for j in enumlist:\n",
    "    y = 'df' + str(i)\n",
    "    y = df_veris.filter(regex = (j))\n",
    "    dflist.append(y)\n",
    "    z = 'dfx' + str(i)\n",
    "    z = pd.DataFrame({j:[]})\n",
    "    dfxlist.append(z)\n",
    "    i+=1\n",
    "for dataframe in dflist:\n",
    "    for col in dataframe.columns:\n",
    "        if  '-' in col:\n",
    "            dataframe.loc[:,col]= dataframe.loc[:,col].apply(lambda x: col.split('-')[-1] if x else '')\n",
    "        else:\n",
    "            dataframe.loc[:,col]= dataframe.loc[:,col].apply(lambda x: col.split('.')[-1] if x else '')\n",
    "m = 0\n",
    "for i,j in zip(dfxlist,dflist):\n",
    "    i[enumlist[m]] = j.apply(lambda x: ','.join(x), axis = 1)\n",
    "    m+=1\n",
    "def get_first(pats):\n",
    "    str1 = ''\n",
    "    pats = str(pats)\n",
    "    pats = [pat for pat in pats.split(',') if len(pat) > 0]\n",
    "    count = 0\n",
    "    for i in pats: \n",
    "        if count==0:\n",
    "            str1 = str1 + i \n",
    "        else:\n",
    "            str1 = str1 + ',' + i\n",
    "        count+=1\n",
    "    return str1\n",
    "for dataframe in dfxlist:\n",
    "    for col in dataframe.columns:\n",
    "        dataframe.loc[:,col] = dataframe.loc[:,col].apply(lambda x: get_first(x))\n",
    "#finallist = list(dfi) + dfxlist\n",
    "Asset_Info = pd.concat([dfi] + dfxlist ,axis=1, sort=False)\n",
    "writer = pd.ExcelWriter(r'Asset_Info.xlsx', engine='xlsxwriter',options={'strings_to_urls': False})\n",
    "Asset_Info.to_excel(writer,index = False)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Asset_Info.rename(columns=lambda x: x.replace('.', '_'), inplace=True)\n",
    "Asset_Info.to_sql(\"Asset_Info\", engine,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_veris.columns = df_veris.columns.to_series().apply(lambda x: x.strip())\n",
    "dfi = df_veris[['incident_id','attribute.availability.duration.value',\n",
    "'attribute.availability.notes',\n",
    "'attribute.confidentiality.data_total',\n",
    "'attribute.confidentiality.notes',\n",
    "'attribute.integrity.notes',\n",
    "'attribute.Confidentiality',\n",
    "'attribute.Integrity',\n",
    "'attribute.Availability'\n",
    "    ]]\n",
    "\n",
    "enumlist = ['attribute.availability.duration.unit',\n",
    "'attribute.availability.variety',\n",
    "'attribute.confidentiality.data_disclosure',\n",
    "'attribute.confidentiality.data_victim',\n",
    "'attribute.confidentiality.data.amount',\n",
    "'attribute.confidentiality.data.variety',\n",
    "'attribute.confidentiality.state',\n",
    "'attribute.integrity.variety',\n",
    "'plus.attribute.confidentiality',\n",
    "'plus.event_chain.attribute'\n",
    "]\n",
    "i = 1\n",
    "dflist=[]\n",
    "dfxlist=[]\n",
    "for j in enumlist:\n",
    "    y = 'df' + str(i)\n",
    "    y = df_veris.filter(regex = (j))\n",
    "    dflist.append(y)\n",
    "    z = 'dfx' + str(i)\n",
    "    z = pd.DataFrame({j:[]})\n",
    "    dfxlist.append(z)\n",
    "    i+=1\n",
    "for dataframe in dflist:\n",
    "    for col in dataframe.columns:\n",
    "        if  '-' in col:\n",
    "            dataframe.loc[:,col]= dataframe.loc[:,col].apply(lambda x: col.split('-')[-1] if x else '')\n",
    "        else:\n",
    "            dataframe.loc[:,col]= dataframe.loc[:,col].apply(lambda x: col.split('.')[-1] if x else '')\n",
    "m = 0\n",
    "for i,j in zip(dfxlist,dflist):\n",
    "    i[enumlist[m]] = j.apply(lambda x: ','.join(x), axis = 1)\n",
    "    m+=1\n",
    "def get_first(pats):\n",
    "    str1 = ''\n",
    "    pats = str(pats)\n",
    "    pats = [pat for pat in pats.split(',') if len(pat) > 0]\n",
    "    count = 0\n",
    "    for i in pats: \n",
    "        if count==0:\n",
    "            str1 = str1 + i \n",
    "        else:\n",
    "            str1 = str1 + ',' + i\n",
    "        count+=1\n",
    "    return str1\n",
    "for dataframe in dfxlist:\n",
    "    for col in dataframe.columns:\n",
    "        dataframe.loc[:,col] = dataframe.loc[:,col].apply(lambda x: get_first(x))\n",
    "#finallist = list(dfi) + dfxlist\n",
    "Attribute_Info = pd.concat([dfi] + dfxlist ,axis=1, sort=False)\n",
    "writer = pd.ExcelWriter(r'Attribute_Info.xlsx', engine='xlsxwriter',options={'strings_to_urls': False})\n",
    "Attribute_Info.to_excel(writer,index = False)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Attribute_Info.rename(columns=lambda x: x.replace('.', '_'), inplace=True)\n",
    "Attribute_Info.to_sql(\"Attribute_Info\", engine,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_veris.columns = df_veris.columns.to_series().apply(lambda x: x.strip())\n",
    "dfi = df_veris[['incident_id','timeline.compromise.value',\n",
    "'timeline.containment.value',\n",
    "'timeline.discovery.value',\n",
    "'timeline.exfiltration.value',\n",
    "'timeline.incident.day',\n",
    "'timeline.incident.month',\n",
    "'timeline.incident.time',\n",
    "'timeline.incident.year',\n",
    "'discovery_method.other',\n",
    "'discovery_method.unknown',\n",
    "'discovery_notes',\n",
    "'control_failure',\n",
    "'corrective_action',\n",
    "'ioc.comment',\n",
    "'ioc.indicator']]\n",
    "\n",
    "\n",
    "enumlist = ['plus.timeline.notification',\n",
    "'timeline.compromise.unit',\n",
    "'timeline.containment.unit',\n",
    "'timeline.discovery.unit',\n",
    "'timeline.exfiltration.unit',\n",
    "'discovery_method.Ext',\n",
    "'discovery_method.Int',\n",
    "'discovery_method.Prt',\n",
    "'targeted'\n",
    "    ]\n",
    "i = 1\n",
    "dflist=[]\n",
    "dfxlist=[]\n",
    "for j in enumlist:\n",
    "    y = 'df' + str(i)\n",
    "    y = df_veris.filter(regex = (j))\n",
    "    dflist.append(y)\n",
    "    z = 'dfx' + str(i)\n",
    "    z = pd.DataFrame({j:[]})\n",
    "    dfxlist.append(z)\n",
    "    i+=1\n",
    "for dataframe in dflist:\n",
    "    for col in dataframe.columns:\n",
    "        if  '-' in col:\n",
    "            dataframe.loc[:,col]= dataframe.loc[:,col].apply(lambda x: col.split('-')[-1] if x else '')\n",
    "        else:\n",
    "            dataframe.loc[:,col]= dataframe.loc[:,col].apply(lambda x: col.split('.')[-1] if x else '')\n",
    "m = 0\n",
    "for i,j in zip(dfxlist,dflist):\n",
    "    i[enumlist[m]] = j.apply(lambda x: ','.join(x), axis = 1)\n",
    "    m+=1\n",
    "def get_first(pats):\n",
    "    str1 = ''\n",
    "    pats = str(pats)\n",
    "    pats = [pat for pat in pats.split(',') if len(pat) > 0]\n",
    "    count = 0\n",
    "    for i in pats: \n",
    "        if count==0:\n",
    "            str1 = str1 + i \n",
    "        else:\n",
    "            str1 = str1 + ',' + i\n",
    "        count+=1\n",
    "    return str1\n",
    "for dataframe in dfxlist:\n",
    "    for col in dataframe.columns:\n",
    "        dataframe.loc[:,col] = dataframe.loc[:,col].apply(lambda x: get_first(x))\n",
    "#finallist = list(dfi) + dfxlist\n",
    "Discovery_Info = pd.concat([dfi] + dfxlist ,axis=1, sort=False)\n",
    "writer = pd.ExcelWriter(r'Discovery_Info.xlsx', engine='xlsxwriter',options={'strings_to_urls': False})\n",
    "Discovery_Info.to_excel(writer,index = False)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Discovery_Info.rename(columns=lambda x: x.replace('.', '_'), inplace=True)\n",
    "Discovery_Info.to_sql(\"Discovery_Info\", engine,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_veris.columns = df_veris.columns.to_series().apply(lambda x: x.strip())\n",
    "dfi = df_veris[['incident_id',\n",
    "'impact.loss.max_amount',\n",
    "'impact.loss.min_amount',\n",
    "'impact.notes',\n",
    "'impact.overall_amount',\n",
    "'impact.overall_max_amount',\n",
    "'impact.overall_min_amount']]\n",
    "\n",
    "enumlist = ['impact.iso_currency_code',\n",
    "'impact.loss.rating',\n",
    "'impact.loss.variety',\n",
    "'impact.overall_rating']\n",
    "i = 1\n",
    "dflist=[]\n",
    "dfxlist=[]\n",
    "for j in enumlist:\n",
    "    y = 'df' + str(i)\n",
    "    y = df_veris.filter(regex = (j))\n",
    "    dflist.append(y)\n",
    "    z = 'dfx' + str(i)\n",
    "    z = pd.DataFrame({j:[]})\n",
    "    dfxlist.append(z)\n",
    "    i+=1\n",
    "for dataframe in dflist:\n",
    "    for col in dataframe.columns:\n",
    "        if  '-' in col:\n",
    "            dataframe.loc[:,col]= dataframe.loc[:,col].apply(lambda x: col.split('-')[-1] if x else '')\n",
    "        else:\n",
    "            dataframe.loc[:,col]= dataframe.loc[:,col].apply(lambda x: col.split('.')[-1] if x else '')\n",
    "m = 0\n",
    "for i,j in zip(dfxlist,dflist):\n",
    "    i[enumlist[m]] = j.apply(lambda x: ','.join(x), axis = 1)\n",
    "    m+=1\n",
    "def get_first(pats):\n",
    "    str1 = ''\n",
    "    pats = str(pats)\n",
    "    pats = [pat for pat in pats.split(',') if len(pat) > 0]\n",
    "    count = 0\n",
    "    for i in pats: \n",
    "        if count==0:\n",
    "            str1 = str1 + i \n",
    "        else:\n",
    "            str1 = str1 + ',' + i\n",
    "        count+=1\n",
    "    return str1\n",
    "for dataframe in dfxlist:\n",
    "    for col in dataframe.columns:\n",
    "        dataframe.loc[:,col] = dataframe.loc[:,col].apply(lambda x: get_first(x))\n",
    "#finallist = list(dfi) + dfxlist\n",
    "Impact_Info = pd.concat([dfi] + dfxlist ,axis=1, sort=False)\n",
    "writer = pd.ExcelWriter(r'Impact_Info.xlsx', engine='xlsxwriter',options={'strings_to_urls': False})\n",
    "Impact_Info.to_excel(writer,index = False)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Impact_Info.rename(columns=lambda x: x.replace('.', '_'), inplace=True)\n",
    "Impact_Info.to_sql(\"Impact_Info\", engine,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_veris.columns = df_veris.columns.to_series().apply(lambda x: x.strip())\n",
    "dfi = df_veris[['incident_id','value_chain.cash-out.notes',\n",
    "'value_chain.development.notes',\n",
    "'value_chain.distribution.notes',\n",
    "'value_chain.money laundering.notes',\n",
    "'value_chain.non-distribution services.notes',\n",
    "'value_chain.targeting.notes']]\n",
    "\n",
    "enumlist = ['value_chain.cash-out.variety',\n",
    "'value_chain.development.variety',\n",
    "'value_chain.distribution.variety',\n",
    "'value_chain.money laundering.variety',\n",
    "'value_chain.non-distribution services.variety',\n",
    "'value_chain.targeting.variety']\n",
    "i = 1\n",
    "dflist=[]\n",
    "dfxlist=[]\n",
    "for j in enumlist:\n",
    "    y = 'df' + str(i)\n",
    "    y = df_veris.filter(regex = (j))\n",
    "    dflist.append(y)\n",
    "    z = 'dfx' + str(i)\n",
    "    z = pd.DataFrame({j:[]})\n",
    "    dfxlist.append(z)\n",
    "    i+=1\n",
    "for dataframe in dflist:\n",
    "    for col in dataframe.columns:\n",
    "        if  '-' in col:\n",
    "            dataframe.loc[:,col]= dataframe.loc[:,col].apply(lambda x: col.split('-')[-1] if x else '')\n",
    "        else:\n",
    "            dataframe.loc[:,col]= dataframe.loc[:,col].apply(lambda x: col.split('.')[-1] if x else '')\n",
    "m = 0\n",
    "for i,j in zip(dfxlist,dflist):\n",
    "    i[enumlist[m]] = j.apply(lambda x: ','.join(x), axis = 1)\n",
    "    m+=1\n",
    "def get_first(pats):\n",
    "    str1 = ''\n",
    "    pats = str(pats)\n",
    "    pats = [pat for pat in pats.split(',') if len(pat) > 0]\n",
    "    count = 0\n",
    "    for i in pats: \n",
    "        if count==0:\n",
    "            str1 = str1 + i \n",
    "        else:\n",
    "            str1 = str1 + ',' + i\n",
    "        count+=1\n",
    "    return str1\n",
    "for dataframe in dfxlist:\n",
    "    for col in dataframe.columns:\n",
    "        dataframe.loc[:,col] = dataframe.loc[:,col].apply(lambda x: get_first(x))\n",
    "#finallist = list(dfi) + dfxlist\n",
    "Value_chain_Info = pd.concat([dfi] + dfxlist ,axis=1, sort=False)\n",
    "writer = pd.ExcelWriter(r'Value_chain_Info.xlsx', engine='xlsxwriter',options={'strings_to_urls': False})\n",
    "Value_chain_Info.to_excel(writer,index = False)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Value_chain_Info.rename(columns=lambda x: x.replace('.', '_'), inplace=True)\n",
    "Value_chain_Info.to_sql(\"Value_chain_Info\", engine,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
